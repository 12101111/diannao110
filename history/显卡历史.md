# 显卡历史

本文以GeForce为界限，之前为古代显卡，通过显卡插槽的接口断代，之后为现代显卡，由于带宽不断增加，接口已经失去意义，只介绍AN两家的各代显卡。

## 1960-1980: 终端

这时还没有PC，只有大型机。早期的大型机没有操作用的显示器，用户需要使用终端与之连接。终端是一种没有微处理器的设备，能与主机通讯并将字符显示出来，并含有键盘以便用户输入字符。最早的终端是TTY（TeletypewriterTele-Type，电传打字机，一种与大型机相连的打字机）。1970年代出现了视频终端，可以将字符转换为视频信号显示在单色显示器上。随后又出现了可以显示矢量图和位图的图形终端。终端最终被PC上的软件telnet、SSH、terminal替代。

## 1980-1990：ISA显卡：显示卡

ISA显卡是IBM PC最初使用的显卡标准。

MDA：Monochrome Display Adapter，单色显示适配器，是1981年IBM在IBM PC上使用的显示卡。它具有80×25的文字分辨率，最高支持720x350的文字分辨率，只能显示单色的文本。

CGA：Color Graphics Adapter，彩色图形适配器，是IBM公司于1981年上市的第一个彩色图形卡，也是第一个IBM PC上的计算机显示标准。标准IBM CGA图形卡具有16KB显存。CGA提供两种标准文字显示模式：40×25×16色和80×25×16色；以及两种常用的图形显示模式：320×200×4色和640×200×2色。

大力神图形卡（Hercules Graphics Card或HGC）是由美国大力神公司于1982年开发的一种单色显卡，分辨率为720x348。在过去个人电脑的早期年代， Herculus卡以较廉宜的价钱、较高的分辨率以及便于编程占据了台湾PC OEM市场。

EGA：Enhanced Graphics Adapter，增强图形适配器是IBM PC计算机显示标准。它是IBM在1984年为其新型PC-AT计算机引入的技术。EGA可以在高达640x350的分辩率下达到16色。EGA包含一个16KB的ROM（只读存储器）来扩展系统BIOS以便实现附加的显示功能，并包含一个Motorola MC6845视频地址生成器。EGA卡所提供的模式有文字和彩色图形两种，它一共有两种文字模式，分别为25列80行及25列40行两种。在640x350高分辩率模式下，EGA仍只支持同时显示16种颜色，但这16种颜色的任何一个可以从64个调色板颜色（每个像素红、绿、蓝各2BIT）中选择一种要显示的颜色。

ATI于1987年推出Wonder系列显卡，为ATI第一代显示芯片，也是世界上第一款零售的独立显卡，被认为是DIY装机的开始。首款产品EGA Wonder使用8位ISA插槽，256KB显存，1微米制程。其性能较IBM的EGA显示卡较强。

VGA：视频图形阵列（英语：Video Graphics Array）是IBM于1987年提出的一个使用模拟信号的电脑显示标准。这个标准已对于现今的个人电脑市场已经十分过时。即使如此，VGA仍然是最多制造商所共同支持的一个标准，个人电脑在加载自己的独特驱动程序之前，都必须支持VGA的标准。例如，微软Windows系列产品的开机画面仍然使用VGA显示模式。VGA曾经被IBM官方宣布使用XGA标准所取代，但在历史上，它其实是被其他的OEM制造商用所谓的SVGA标准所取代。VGA中的A指的是“阵列（array）”而非“转换器（adapter）”，因为它从一开始就被设计为一个单一的集成芯片，用来取代Motorola 6845和数十个离散的逻辑芯片组合而成的ISA主版。VGA的这个特性允许它轻易的植入PC的主板之中，只需要额外的显存、时钟器和一个RAMDAC（将调色板信号转换为模拟信号的芯片），就具备显示功能。IBM PS/2电脑系列就是采用将VGA放置于主板上的设计。

标准的VGA文字模式使用80×25或40×25个字母或数字组成的平面。每个字符的块状区域可以选择16种前景色和8种背景色.而字符本身也可设置是否闪烁，而字符的闪烁动作都是同时的。画面的闪烁功能和选择背景颜色的功能是可交换的，换句话说两者只能择一。VGA将调色板扩充成256种颜色，但为了向前兼容，一次只能选择256种之中的64种。VGA限制颇多，被分辨率更高的标准所取代。

VGA端子（Video Graphics Array (VGA) connector），其他的名称包括RGB端子，D-sub 15，或mini D15，是一种3排共15针的DE-15。VGA端子通常在电脑的显示卡、显示器及其他设备。是用作发送模拟信号。VGA虽然被SVGA所代替，但VGA端子被继承下来，成为使用极广的模拟视频信号接口。

SVGA（Super Video Graphics Array，常常被缩写为Super VGA）是一个涵盖大范围的电脑显示标准。

原本SVGA是IBM用来扩充1987年推出的旧VGA标准而提出的新标准。它不像之前完全由IBM独自制定的VGA标准，SVGA是由VESA组织所制定，而VESA（Video Electronics Standards Association）是一个开放的组织，它为了促进各个标准的协作并制定新的标准而努力着。SVGA用来指称分辨率时，通常就表示800×600的分辨率。SVGA第一次制定于1989年。在这个版本中，它要求了800×600的像素平面，而色彩深度为4-bit，也就是说一个像素将可为16种索引色彩中的任何一种。这个条件后来又被提高至1024×768和8-bit（即256色），在接下来几年，对分辨率和载色度的要求仍不断提升。

虽然VGA或者SVGA的输出是模拟的，但电脑内部的处理回路无论如何都是完全数字的。增加可显示的颜色数后，在显示器端不需要任何的修改，但在显卡端却将需要处理更大数字的能力，甚至面临重新设计整个主板。即使如此，在SVGA标准推出后个数个月内，先进的制造商仍能够顺利推出能够显示SVGA的显卡。

在原本的计划中，SVGA预定为SXGA（Super XGA）标准所取代；但实际上在此以后，工业界放弃了为每个更高标准给定独特命名的企图。几乎在1990年后期至2000年前后，显卡能表现出的各种显示规格都被归类在SVGA中。

ATI于1988年推出ATI VGA Wonder，使用16位ISA插槽，512KB至1MB显存，1微米制程。ATI称之为VGA card,完美支持VGA标准。

扩展图形阵列（Extended Graphics Array或XGA）是IBM在1990年推出的一个标准。XGA支持1024×768分辨率，256色调色板（每像素8比特），或者640×480分辨率（每像素16比特，或称增强色）。XGA-2更进一步支持1024×768（增强色），和1360×1024分辨率（每像素4比特，16种颜色可选）。

尽管PC出现后的10年内，显卡制造商努力的提高显存的大小，但当时拥有一张彩色图形卡仍是较为奢侈的事情，大多数PC用户仍然使用黑白界面，DOS系统与单色显示器，直到1991年Windows3.0发布，Windows才真正开始流行。

## 1990-1995：VLB显卡：2D加速卡

Video Electronics Standards Association（视频电子标准协会，简称“VESA”）是制定计算机和小型工作站视频设备标准的国际组织，1989年由NEC及其他8家显卡制造商赞助成立。创立VESA的原始目的是要制定分辨率为800x600的SVGA视频显示标准以便取代IBM的VGA标准。其后，VESA公告一系列的个人电脑视频周边功能的相关标准。

由于ISA较小的带宽影响了显示技术的发展，VESA还推出了VESA总线（VESA本地总线，VESA Local Bus，简写为VL-Bus或VLB）以扩展标准工业插槽的带宽。VLB插槽本身就是既有ISA插槽的延伸，伸长的部分通常被涂成棕色，和一般黑色ISA插槽区别。VLB扩充的插槽也可以当作ISA插槽使用。由于VLB伸长自ISA，所以VLB扩充卡都十分的长，与老式的IBM XT扩充卡相似。而伸长的部分则和之后的PCI插槽相似。VLB当初即被设计为一个过渡性的规格，以扩展ISA有限的带宽，因此它有数个限制其后来潜力的瑕疵。

其中最大的就是80486 依赖性：VLB重度的依赖80486的内存总线设计。当奔腾在1995年推出时，它的总线设计与486有很大的不同，而VLB并不适应这样的设计，这也造成要移植VLB到其他平台几乎不可能。此外VLB接口极其耗电，一台PC最多只能安装3个VLB插槽。造成插槽限制的电力问题同样也造成了其他问题。扩充卡之间会有相互干扰的问题，尤其对低阶的主板而言更是如此。当一些重要的装置如硬盘控制器受到干扰时，很有可能发生大规模的资料损失。它的长度和针数的数量，使VLB扩充卡有难以安装和拆除的恶名。用户必须施以很大的力量，对于扩充卡和主板来说都是很大的压力，也常常造成元件的断裂。还有的机箱空间不足容纳VLB扩充卡，或者由于空间不足而难以安装的例子。VLB这个缩写有时被戏称为very long bus。

即使有这些问题，VLB在486主板上十分常见，也许有半数的486系统都装有VLB显卡。不过，早期的486系统并没有VLB，因为它在数年后才出现。随着奔腾和Intel的PCI标准的提出，部分486主板后期也开始使用PCI代替VLB。

在之前显卡的唯一功能就是输出图像，真正的图形运算全部依赖CPU，所以当微软Windows操作系统出现后，PC的CPU开始不堪重负了。可能很多人难以理解图形界面为什么会如此消耗资源，但您一定有过这样的经历：如果不装显卡驱动的话，比如在Windows安全模式下用鼠标快速拖动窗口，您会发现这个操作非常卡顿， 无论CPU多么强大都无济于事。

1991年，S3 Graphics推出了PC上第一款的2D图像加速器，名为S3 86C911，其后，86C911催生了大量的仿效者。此显卡通过一颗专用的芯片来处理图形运算，从而将CPU解放了出来，让Windows界面运行起来非常流畅，从此图形化操作系统资源消耗大降、实用性大增。

泰鼎微系统（Trident Microsystems, Inc.）创立于1987年，当时在制造、销售廉价但性能普通的SVGA显示芯片上颇有声誉。但2D加速卡出现后，泰鼎没有推出性能较好的2D加速芯片。

ATI于1991年推出Mach8架构的2D绘图加速器，需要与显示卡一同使用，这是ATI第二代产品，也是第一代专为Windows优化的产品。ATI支持ISA、MCA、VLB接口。Mach8显卡是由两颗芯片组成的，主芯片为上一代的VGA  Wonder XL 24（ATI  28800-6），负责显示输出，辅助芯片是Mach8（ATI 38800-1），专门加速Windows图形界面，通过双芯片的设计增强了绘图能力。

1992年，ATI 推出第三代产品Mach 32，支持32bit真彩输出，加入了对Linux操作系统的支持，拥有2MB显存。

Mach 64芯片是ATI的第四代产品，于1994年8月推出。它的特色是硬件支持视频加速、YUV／RGB颜色转换和硬件缩放。Mach 64显卡取代了昂贵的专用视频解码器，使个人电脑能播放AVI和MPEG-1视频。Mach64-VT于1996年推出，功能与Mach 64相似，但硬件支持逐行扫描，减低CPU的负担。它还支持800×600分辨率的VGA／TV编码。

这段时间内，PC上的图形应用越来越多，图形游戏也在PC上出现。

AutoCAD为当时对显卡要求较高的程序也是少数能成功由DOS过度至WINDOWS的软件绘图软件。

由于早期PC性能较低，且Windows3.x消耗资源较大，PC游戏多运行于DOS平台，独占所有硬件资源

当时的知名PC游戏（部分首发于家用机）：

    模拟城市 (1989年)（EA）
    大富翁（1989年）（大宇资讯）
    轩辕剑（1990）（大宇资讯）
    文明（1991年）（席德·梅尔）
    失落的维京人（1992年）（暴雪）
    沙丘II 新王朝（1992）（西木）（RTS）
    德军总部3D（1992年）（id Software）（FPS）：据信是第一款商业化的FPS.尽管关卡以三维角度呈现，但敌人和物品都是从多个视角以二维呈现（纸片人），这种技术有时被称为2.5D图像。
    毁灭战士（1993年）（id Software）（FPS）：它使用了包围游戏角色的3D环境绘图、多人游戏支持，并有支持玩家自制扩展包的WAD架构。
    FIFA国际足球（1993）（EA）
    上古卷轴：竞技场（1994年）（Bethesda）
    极品飞车 （1994年）（EA）
    魔兽争霸：人类与兽人（1994年）（暴雪）（RTS）
    魔兽争霸II：黑潮（1995年）（暴雪）(RTS)
    命令与征服：泰伯利亚黎明（1995）（西木）(RTS)
    仙剑奇侠传 （1995）（大宇资讯）
    中关村启示录，中国内地第一款比较正式的商业游戏软件。由金山软件公司的全资子公司——西山居制作。是一款经营策略类的游戏。它于1995年3月开始制作，1996年1月发行。它运行于DOS平台。
    侠盗猎车手 （1997年）（Rockstar ）

毁灭战士之所以如此独特在于当时看起来相当卓越的3D图形，和无与伦比地在消费性个人电脑上做出即时运算。这个进步比毁灭战士的前身德军总部多出了一些特性：

    高度差异（所有德军总部的房间都在同一水平在线）。
    非垂直的墙壁（所有德军总部的墙都成矩形的）。
    武器的晃动（在德军总部中，不论玩家做什么事，武器的位置总是固定在画面的特定部分），这给了玩家正在移动的印象。
    所有表面都可贴图（在德军总部中地板和天花板是没有贴图的）。
    光线的差异（在德军总部中所有的房间都呈现同样的亮度）。
    借由成功的由光线和阴影制造视觉上的错觉，足以改变玩家在探索游戏世界的态度，
    阴暗未知的元素可以给予玩家惊吓或者困惑，这大概会被认为是最为重要的一个改变。
    和德军总部的呆滞比起来，毁灭战士的元素是高度互动化的：
        可以上升或下降的平台、
        原本水平的地板可以相继上升而形成楼梯、桥梁也是同样。
        而游戏提供立体声音效使游戏的经验贴近了现实世界，借此玩家甚至可以听到怪物的方向和距离。
        玩家必须时时警觉怪物们的嚎叫和怪吼，而怪物也同样会被玩家的枪声而开始警觉
        玩家也可以借由机关的声音来发现一些秘密的房间。

约翰·卡马克使用了一些技巧才能使这个游戏在1993年的电脑上运行。最明显的特征是，毁灭战士不是真正的三维空间环境，它们仍然呈现（数学上的）平面，只是随后加上的高度参数让游戏引擎来产生高度差异。

id Software：id Software是一家在美国得克萨斯州的电子游戏开发公司。公司除了从事电脑游戏的开发以外，亦有自行研发游戏引擎。知名的第一人称射击游戏大作早期版的《半条命》和早期版的《反恐精英》（Counter-Strike，简称CS）就是利用Quake的引擎制作的。该公司在1993年推出的作品《毁灭战士》（DOOM）彻底改变了电脑游戏产业，在当时有着里程碑的意义。在2004年该公司推出的作品《毁灭战士III》在E3游戏大展上也获得了巨大成功，包揽了5项大奖。

传奇人物：约翰·卡马克

卡马克最让人咋舌的冒险就是涉足了第一人称射击游戏领域。他的编程能力毫无保留的体现了出来，随后的《德军总部3D》（Wolfenstein 3D）、《毁灭战士》（Doom）和《雷神之锤》（Quake）就是最好的佐证。这些游戏和它们的后续版本都获取了巨大的成功。

卡马克喜欢在电脑图像领域尝试新的技术，比如他在Doom上第一次使用了二叉树分区技术，表面缓存技术则在Quake中第一次出现。还有就是后来在Doom3里面使用的“卡马克反转”（即shadow volume的z-fail方法。事实上并不是卡马克首先创新了这个技术，他在后来独立研究出来。）。

卡马克创造的游戏引擎被用来制作其他的第一人称射击游戏，比如《半条命》（Half-life）和《荣誉勋章》（Medal of Honor）。

卡马克是一个众人皆知的开源软件的倡导者，他也再三强调反对“软件专利”，但是他一直处于势单力孤的状态。
卡马克在1995年放出了德军总部3D的源代码，之后的1997年又放出了毁灭战士的代码。1996年时候，他放出了雷神之锤的源代码，Quake社区中的一名不太出名的程序员将其改写成了Linux版本，并且将修改后的游戏发给了卡马克。卡马克没有认为这是侵权行为然后付诸法律，而是要求id Software的员工们用这个补丁作为雷神之锤linux版本的基础。id Software在后来的日子里也同样公布了雷神之锤II的代码，雷神之锤III的代码也于2005年8月19日公布，这些代码的公布全遵循了GPL准则。毁灭战士的代码也使用GPL准则在1999年重新公布。

2013年8月7日，卡马克以首席技术官（CTO）身份加入Oculus VR公司，并在同年11月22日正式从id Software辞职以全职供职于Oculus VR。卡马克辞职的原因是id的母公司ZeniMax Media不赞成id在Oculus Rift这个平台上发展游戏。

卡马克广泛使用了平方根倒数速算法，这是其3D FPS能在当时的配置下运行的原因。

    float Q_rsqrt( float number )
    {
        long i;
        float x2, y;
        const float threehalfs = 1.5F;
        x2 = number * 0.5F;
        y  = number;
        i  = * ( long * ) &y;                       // evil floating point bit level hacking
        i  = 0x5f3759df - ( i >> 1 );               // what the fuck?
        y  = * ( float * ) &i;
        y  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration
        //  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed
        return y;
    }

## 1995-1999：PCI/AGP显卡：3D加速卡

PCI显卡使用于486到PentiumII早期的时代。1993年4月30日， PCI 2.0标准发表后， PCI标准则缓慢地取代着VESA局部总线（VLB）；至1996年，英特尔推出奔腾（Pentium）CPU后，由于VLB无法支持新架构的奔腾处理器，VLB随着奔腾I的留下退出历史舞台。后期的80486主板除了VLB以外，也都搭配了PCI插槽。

AGP，全称为加速图形接口（Accelerated Graphics Port），是电脑主板上的一种高速点对点传输通道，供显卡使用，主要应用在三维电脑图形的加速上。AGP是在1997年由Intel提出，是从PCI标准上创建起来，是一种显卡专用接口。其出现是因为PCI的带宽不足以支撑发展迅速的显卡。1997年10月中旬，Intel于i440LX Slot 1芯片组上加入AGP的支持，其后主要主板供应商也大量推出一系列相关的产品。微软首次推出AGP支持是在Windows 95 OEM Service Release 2版（OSR2 version 1111或950B）上,首个支持AGP的Windows NT核心操作系统版本，是1997年发表的Windows NT 4.0 Service Pack 3。而Linux于1999年通过AGPgart内核模块加入对AGP高速数据传输的支持。相比起PCI，AGP可把帧缓冲内存更有效地使用，除3D绘图外，2D绘图的表现也得以加强。

到了90年代中期，图形技术的发展达到了一个新的顶峰，传统的2D显示技术早已不能满足人们的需求了，而整个图形技术领域也在酝酿一场革命。一方面PS等游戏机的面世收到了数以万计玩家的追捧，当时的图形厂商也看到了游戏市场的巨大利润，不过同时代的PC图形处理能力与前者还有很大差距，迫切需要强大图形运算能力的显卡加入;另一方面，游戏领域已经萌发了3D的雏形，事实上当时PS等游戏机上已经出现了少量的3D游戏，并且吸引了一大批玩家。由此，2D到3D转变迫在眉睫。在那个群雄逐鹿的年代，众多图形厂商都纷纷推出旗下的第一代3D显示卡，例如NVIDIA的NV1、Matrox的Mlennium以及Mystique、PowerVR的PCX1、S3的Virge3D等等，并冠以“3D加速卡”的美名。不过那时所谓“3D”严格来讲只能算是“2.5D”，它们提供的3D加速功能相当有限，而且图形应用程序接口也都是自家定制的API，各自为战。这些芯片主要是在上一代的2D加速器上加入三维功能，有些芯片为了便于制造和花费最低成本，甚至使用与前代兼容的针脚，因此，这些显卡基本上比较失败。

在九十年代初，S3曾经称霸整个显卡市场。1994年，S3凭借2D图像速度的优势，成功击败当时另一巨人泰鼎微系统，成为主流显卡市场的领跑者。好景不长，3D应用快速普及，只是2D强劲是无用的。在1996年，nVIDIA RIVA TNT、Matrox G200、3dfx Voodoo等强劲3D加速卡的到来，S3仓促将S3 Savage 3D投入市场。ViRGE，全称为"Video and Rendering Graphics Engine"（视讯描写图形引擎），是S3第一代电脑的2D／3D加速卡，于1995年由S3公司推出。ViRGE为2D及DRAM帧缓冲显卡带来了新标准，而一个循环的EDO计时使得当时的ViRGE/325成为了最高评分的DRAM基础2D加速卡。但在3D加速方面，ViRGE使不少用户感到失望。随后S3推出Savage 4系列显卡，对抗nVIDIA RIVA TNT2和Matrox G400，但是驱动问题始终无法解决，翻身作惨淡收场。尽管S3推出后继产品Savage 2000，但究竟不能替S3挽回败局，最后更被VIA以3.22亿美元收购。VIA收购S3只是想获取其显卡技术，将它融合在集成型主板，S3的独立显卡产品发展受阻。

同期的Matrox公司的Millennium系列显卡在2D方面的速度、质量都有极佳的表现，很长一段时间，Matrox的显卡一直有着最佳的2D显示性能，不过在3D显卡方面的性能、市占都逐渐落后于其它业者，虽然该公司曾努力维持自身在产业界的地位。最后，Matrox转到的专业视频需求市场，导致了后来在整体显卡市场中仅剩不足1%的占有率。

PowerVR是Imagination Technologies的软硬件视频处理开发部门，也是其设计的图形芯片的常用名称。在1990年代后期，它的3D领域主要竞争对手是3dfx的Voodoo系列显卡。其后在ATi和Nvidia的激烈竞争中没落。此后PowerVR主力发展低功耗市场。今天，很多移动设备，游戏机上都能发现PowerVR的身影：在2010年，全球售出了超过2.15亿枚包含PowerVR技术的芯片。2017年4月3日，Imagination Technologies重要客户苹果公司宣布两年后将不再继续使用Imagination显示技术，包括专利、知产、保密信息等等。此举导致Imagination Technologies股价暴跌60%。2017年九月发布的Iphone8采用了苹果自研的显示芯片。

NV1是由NVIDIA用了两年时间研发，于1995年5月推出的显示芯片，它亦是NVIDIA自创立起的首款产品。但这款产品既不支持DX，也不支持OpenGL，因此十分失败。NV2开发随后取消。

RIVA 128是nVIDIA的第三代显示芯片，核心代号NV3，于1997年底完成一百万颗出货量。经历了NV1、NV2的失败后，NVIDIA集中力量研发NV3，进攻个人电脑市场。当时适逢微软发展Direct 3D，各家显示核心厂商也准备发展各自的显示标准，例如3dfx的GLIDE、PowerVR的PowerSGL、ATi的3DCIF。而NVIDIA则支持微软的Direct 3D标准，从而有了微软强大的后盾。RIVA 128的效能超越了3dfx的Voodoo和ATI的Rage Pro，纵使画质一般，但价格低廉，成OEM的最爱。

1996年ATI第一款3D显示芯片ATI 3D Rage正式面世，2D核心继承于Mach64，并增加了3D处理功能，制程为0.5微米，配备了2MB的显存，并支持MPGE-1硬件加速，不过虽然它提供了诸如光源处理之类的3D加速特性，但却不支持硬件Z-buffer，所以还算不上真正意义的3D显卡。然而最致命的还在于3D Rage存在严重的兼容性问题，致使市场接受度极低。

3D Rage由于兼容性问题很快淡出市场，不过ATI并没有因此收到太大影响。并于6个月后的1997年推出了全新改进的3D Rage II 。虽然从命名上看这似乎是ATI的第二代3D图形加速显卡，但事实上它才是真正意义上的第一款3D芯片。3D RAGE 2修正了上代产品致命的兼容性问题， 2D方面采用了重新设计的MACH 64 GUI引擎，性能得到提升。显存方面搭配了2～4MB的单循环EDO或高速的SGRAM。3D RAGE II芯片的另一个增强，是3D RAGE的座脚兼容加速版。而第二代的PCI总线令它的2D性能增加了20%，此外还新增了MPEG-2 (DVD)播放功能。这款芯片还支持微软Direct3D、Reality Lab、QuickDraw 3D Rave、Criterion RenderWare和Argonaut BRender的驱动程序。专业的3D和CAD用户可得到OpenGL驱动程序，AutoCAD用户可得到Heidi驱动程序。驱动程序亦支持数个操作系统，包括Windows 95、Windows NT、Mac OS和OS/2。ATI还配备了RAGE II的ImpacTV电视编码芯片。总的来说3D Rage II支持双线性、三线性过滤、Z-buffer和一些Direct3D材质混和模式，不过像素过滤只是比S3的ViRGE略好，相比当时的其它产品只能算是中规中矩。ATI在多媒体视频方面的天分始于MACH 64。从这个时期开始，ATI的视频技术就不断积累革新，特别是在DVD解压方面颇有建树。3D Rage II同样继承了MACH 64-VT的视频技术。而此后的3D RAGE II + DVD更是业界首款具备动态补偿(motion compensation)的图形芯片，此举大幅降低CPU在做软解压DVD时的负担。虽然后来在1998年S3的Savage 3D曾一度抢了DVD视频回放加速之王的桂冠，但很快ATI就以RAGE 128GL革新的硬件iDCT(inverse discrete cosine transfer逆离散余弦)一举夺回DVD加速之王的头衔，而这一技术也延续了将近两年 。

Voodoo是3dfx第一款纯3D加速芯片，它并非单独的显示卡，而是一块3D子卡，需要配合2D显示卡使用。Voodoo在市场上非常受欢迎，即使其售价和性能高于同时期的RIVA 128、i740。

3dfx Interactive是一家专门制造显卡和GPU的公司，于1994年成立。1996年成为此领域的最初垄断者，其后期产品的设计循规蹈矩，创新力大减，热衷于制造多芯片技术（SLI），导致产品效能极低，最终导致其公司的破产并被竞争对手NVIDIA并购（2000年末）。

Voodoo Rush是3dfx第一款2D+3D显示卡，可单独使用，其2D芯片采用的是Alliance生产的AT3D，但性能与兼容性不佳，销售亦不好。

Voodoo 2是3dfx第二款纯3D加速芯片，同样须有2D卡配合使用。性能大幅优于Voodoo，且高于同期对手芯片，销量亦极佳，堪称3dfx最卖座的芯片。另外，其支持SLI技术，可以将两块Voodoo 2同时使用，速度远超同期芯片，而且甚至可以与 Voodoo 3相比。

Voodoo 3是3dfx第一款真正全新设计的2D+3D芯片。性能与同期产品相近，但仅支持16bit和16MB显存，而且仅是将接口改为AGP 2X（亦有PCI版本），不支持AGP 2X的绝大多数特性，导致性能略输。

Intel740（常被简称为i740）是英特尔公司研发的显示核心。它是英特尔唯一一款被用于独立型显卡上的显示核心，于1998年2月正式发布。在游戏应用中，i740的性能约为Voodoo2的一半。i740的一个目的是推广AGP标准。i740是第一款AGP 2X显示卡，i740的高销量使其他显示核心厂商接纳AGP标准。Intel原先预计i740有不错的性能，可惜事与愿违，不能在独立显卡市场获取一席之地。亦令Intel意识到主流市场才是其目标。其后，Intel将i740图形核心集成到芯片组内，成为i810和i815集成式芯片组，再度提高其市场占有率。i740亦为其后Intel成为市场一哥奠下良好基础。i740使Intel成为低级显卡市场的霸主，间接迫使S3 Graphics（旭上）和Trident Microsystem（泰鼎）从显卡市场败退。最后S3被VIA并购；Trident则是将显卡部门售予SiS，转往DVD/HDTV/Video视频处理芯片方面发展。

1998年，3D显卡大战也愈加白热化。此时的NVIDIA、3DFX、MATROX、S3、ATI等厂商纷纷拿出自己的绝活，推出了一系列优秀的产品。

1998年4月，ATI推出了第三代的RAGE显示芯片——3D Rage Pro。ATI为这款芯片新增了三角形设定引擎，并且透视法修正算法也得到了改进，同时增强距离模糊和透明化效果。此外还新增了反射高光效果和增强了影像播放功能，尤其是DVD播放。3D Rage Pro芯片的另一大卖点是首次加入了对Intel的AGP接口的支持，支持边带寻址和AGP 2X。3D Rage Pro支持最高8MBSGRAM或16MBWRAM。AGP总线的高带宽特性令Rage Pro的MPEG-2加速性能得以提升，使得ATI当时的DVD回放性能更进一步。这使得ATI得到了更多OEM厂商的重视，大批的OEM订单使ATI公司在1998年的收入也翻了一番。

RIVA TNT是nVIDIA研发的显示芯片，核心代号NV4，于1998年10月发布，支持DirectX 5和OpenGL 1。这个系列被称为“3dfx的终结者”。TNT是TwiN Texel的意思。TwiN Texel就是拥有2条32位像素流水线的架构，每条流水线有1个TMU，每个周期可并行处理两个像素，所以显示核心时钟达90MHz的RIVA TNT填充率能达到250M Texels/s；同时它还首次拥有24位深度缓冲，并拥有16MB显存。NVIDIA的目标是让RIVA TNT的效能能达到3dfx Voodoo2的两倍。但受制于0.25微米制程还没有成熟，RIVA TNT的制造工艺是0.35微米制程。这令到核心频率比原先预计的110MHz大幅降低，只有90MHz，在这一频率上RIVA TNT的综合效能并不及Voodoo2。RIVA TNT是当时最快的显示核心之一，多间显卡厂商都加入了NVIDIA阵营，包括德国的Elsa和美国的Canopus。同期，NVIDIA成为OpenGL Architecture Review Board（OpenGL ARB）的成员。后来，NVIDIA意识到驱动程式的重要性，开始为RIVA TNT编写全新的驱动程式，这就是著名的“雷管”（Detonator）。随后NVIDIA更新了TNT的制程，由0.35微米提升到0.25微米。最终，TNT的核心频率是125 MHz，Ultra版本则是150 MHz。Voodoo 3只是勉强比TNT快，而且不支持32-bit色彩质量。RIVA TNT－建基于NV4，支持DirectX 6和OpenGL 1.1，这个显卡系列使nVIDIA成为市场领导者。RIVA TNT2－核心代号NV5，支持DirectX 6和OpenGL 1.1。拥有128位3D架构。 Vanta－核心代号NV6，支持DirectX 6和OpenGL 1.1。是一颗128位TNT架构的低成本绘图处理器。

Rage 128是ATI首枚128bit 3D芯片，支持AGP 4X接口、硬件MPEG-2加速。该产品的一大卖点就是专门为32bit色设计，从16bit色到32bit色的性能下降不到5%，这在当时是相当惊人的。在性能上，ATI推出的RAGE 128并不是当时顶尖的，不过RAGE 128胜在各项性能指标都非常平均。不仅在DVD动态插值补偿方面依然占据优势外，更有支持VIVO和ALL-IN-WONDER的显卡版本。在当时看来，这已经算是功能非常强大的多媒体显卡。Rage 128也分为高低型号，以面向不同用户群。当时型号非常多，包括Rage 128 VR、Rage 128 GL、Rage 128 GL、Rage 128 Pro等。

## 1999-今 PCI\APG\PCI-E:现代GPU

1999年显卡界发生了一件大事。

NVIDIA于1999年8月发布GeForce 256（核心代号NV10），由NVIDIA研发的第五代显示核心。此核心常简称为GeForce，这亦是NVIDIA第一个以"GeForce"为名的显示核心。GeForce 256与前代（RIVA TNT2）相比增加了Pixel Shader流水线的数目，支持硬件T&L（坐标转换和光源）引擎，支持DX7和OpenGL 1.2，亦支持MPEG-2硬件视频加速。GeForce 256凭着它的功能和速度，在各路厂商的竞争中获取了很好销量，令NVIDIA的电脑图形工业霸主地位更坚固。NVIDIA的成功，使3dfx，Matrox和S3 Graphics都成了牺牲品。一年后，只有ATi的Radeon显卡能有实力孤军作战。

NVIDIA在产品宣传中，称GeForce 256为世界上第一个GPU，这是NVIDIA首创的词汇，GPU即是Graphics Processing Unit的缩写。后期NVIDIA亦以GeForce 256为基础，首次为专业工作站生产Quadro。Quadro拥有一些平民GeForce没有的特别功能。由于采用相同显示核心，很多人发现GeForce 256经过修改也能很好的处理工作站应用，价格亦比Quadro便宜。緃使GeForce 256是一张昂贵的游戏卡，但比专业卡便宜得多，被誉为"平民专业卡"。

GeForce  256是被作为一个图形处理单元(GPU)来设计的，GPU是一个单芯片处理器。它有完整的转换、光照、三角形设置和渲染引擎(分别 为:Transform、Lighting、Setup、Rendering)等四种3D处理引擎，一些以前必须由CPU来完成的图形运算工作现在可以由GeForce256  GPU芯片独立完成，大多数情况下具有完整的传输和光照相引擎的GPU运算速度比CPU快2-4倍，同时也有效地减轻了CPU的浮点运算负担，减少了对CPU的依赖性。

GeForce 256显示核心采用0.22微米制程制造，是256-bit显示架构，拥有4条像素流水线。每一条有4个像素单元，1个材质单元。三角形生成率是每秒1500万个，像素生成率则是每秒4亿8000万个。它拥有2300万个晶体管，数量已超过了PentiumIII，本应采用0.18微米制程去解决热量问题，但为了加速上市，唯有采用旧的工艺。但凭著四条像素流水线，性能依然强劲。GeForce 256一般配置为32MB SDRAM（中高端）或DDR SDRAM（高端）。，GeForce 256的内存带宽是相当不足的，尤其是SDRAM版本，令它达不到应有的性能。

由于GeForce的成功，微软请来nVidia为第一代Xbox研发绘图引擎。

GeForce 2（核心代号为NV15），是由NVIDIA设计的第二代GeForce显示核心，于2000年4月26日推出。其后推出了首款应用于笔记本电脑的显示核心GeForce 2 Go系列。GeForce 2更新了视频处理管线，名为HDVP (high definition video processor)，支持高分辨率动态视频播放。由于其纹理处理性能强大，开发者利用纹理环境参数和纹理函数，就可以作出一些数学运算。这通常用于求数学上扩散方程的解。这是通用显示核心（GPGPU）的最早利用。支持DirectX 7，OpenGL 1.2。

ATI Radeon 7000系列显卡，显示核心代号Radeon R100，由ATI研发并在2000年中旬正式发布。当时桌面图形卡市场只剩下ATI和NVIDIA两家公司，NVIDIA发布GeForce 256和GeForce 2。面对着nVidia的攻势，ATI发布Radeon R100显示核心，首款采用此核心的是Radeon 256显卡。Radeon R100首次支持DirectX 7。它支持T&L，硬件几何变形，光照效果，和图象剪切。它亦首次使用DDR作为显存。这些功能使Radeon在性能上可与GeForce 2一决高下。ATI Radeon 7000系列显卡是ATI最成功的一款显卡之一，现今ATI显卡继续使用Radeon这个名字。

GeForce3（核心代号是NV20）是nVIDIA发明的第三代显示核心。在2001年2月的Macworld Expo Tokyo 2001上发布。它是全球第一款支持DirectX 8的显示芯片，同时支持OpenGL 1.3。它拥有4条像素流水线，可同时处理最多8个纹理，即4×2架构，像素填充率是800 Mpixels/s。GeForce3上还采用了更先进的反锯齿技术，如超采样反锯齿。最大改进之处是其可编程T&L技术，对很多光影效果提供硬件支持。GeForce3没有推出移动平台的产品，其专业版名为Quadro DCC，基于GeForce3标准版。GeForce3还支持内存带宽节省技术。

ATI Radeon 8000系列显卡，采用R200系列显示核心，由ATI研发并推出。Radeon 8500（核心代号 R200）是一个Radeon系列显卡核心能够将ATI放在与nVIDIA竞争的层面上，亦成功使当时的ATI脱离衰退显卡厂商的行列。它亦是全球首款完整支持DirectX 8.1的产品，GeForce 3只能支持DirectX 8.0。

GeForce 4（核心代号是NV25）是nVIDIA研发的第4代绘图处理器，发布于2002年。架构实际基于GeForce3改进而成。它拥有4条像素流水线，每条流水线包含2个材质贴图单元，即4*2架构。T&L方面，GeForce4采用了nfiniteFX II引擎，它是从GeForce3的第一代发展而成。GeForce4 Ti配备了两个顶点着色引擎，比旧的GeForce3多了一个，这表示同一时间可以处理更多顶点。这并不是全新的设计，皆因Xbox中的显核亦使用了个顶点着色引擎。纵使GeForce4架构与GeForce3分别不多，但是依然有性能提升，原因是功能的改进与微调。GeForce4系列有三个分支，分别是高端的Ti，较低端的MX。该系列最后发表的PCX 4300是加入HSI桥接芯片以支持PCI-E接口的绘图处理器。Ti系列支持Direct3D 8.1于OpenGL 1.4。

ATI Radeon 9000系列显卡，采用Radeon "R300" 架构显示核心，2002年8月推出，是ATI的第一个支持DirectX 9.0的显示核心，亦是全球第一个完全支持DirectX 9的绘图核心。它让ATI在1999年的GeForce 256以来，在性能上首次胜过NVIDIA。R300和其派生产品形成了ATI的消费级和专业级产品线的生命周期足有三年那么久。

GeForce 5（官方统称为GeForce FX系列）是由nVIDIA研发设计的第五代GeForce显示核心产品，分为两大系列：

GeForce FX（核心代号NV3x）在2002年11月18日的COMDEX展上发布。GeForce FX 5800 Ultra与FX 5800是全世界首款支持DDR2显存的显卡。它使用了当时许多超前的技术，其采用CineFX 2.0引擎，首次支持CG高级编程语言，亦完全支持Direct 9.0。NV30芯片是全新设计的，与NV25极少有相似之处，而晶体管数量是上一代NV25/NV28的两倍。2003年3月19日，NVIDIA发表该系列的移动版GeForce FX Go，最初发表有五款产品FX Go 5700、FX Go 5650、FX Go 5600、FX Go 5200、FX Go 5100，同年9月发表了建基于NV3x系列的Personal Cinema FX数字娱乐解决方案。

GeForce PCX（核心代号NV3xPCX）在2004年2月17日的IDF2004上正式发布。是业界第一套全系列支持PCI-E接口的GPU。但GeForce PCX只是GeForce FX系列显示卡配合HSI桥接芯片,将原本为AGP接口而设计的显式卡，用该桥接芯片转接至PCI-E插槽，性能瓶颈依旧存在，所以GeForce PCX只是理论上支持PCI-E，完全不能发挥PCI-E应有效果。GeForce PCX名副其实是过渡产品。

GeForce 5核心以TSMC0.13微米制程制造。与前代0.15微米制程相比，新的制程可使晶体管缩小25%且快上25%。但NV30结构复杂，导致成品率较低。而128位的显存频宽严重跟制了其性能，由于核心频率高，所以发热量也高。而必须采用更强的散热风扇。然而该散热风扇噪音过高,且需多占用一条PCI盘，成为该产品所诟病的缺点。GeForce 5后期型号众多，定位有部分重叠。

另外，GeForce FX运行温度很高，毕竟他们消耗了两倍于同等AMD显卡的电能，曾经多次发生过自燃事故而被人讥称为“战术核弹”。GeForce FX 5800 Ultra显卡也因为其风扇噪音而声名狼藉，并因此得到了“吸尘器”、“吹风机”的诨号。NVIDIA为此通过加大散热风扇，用更静音版本替换了早先版本。但是这也让显卡制造商面对AMD的显卡失去了价格优势。其最终结果，由于FX系列显卡的羸弱，导致NVIDIA始料未及的将显卡市场的领导地位易主AMD。

Radeon X Series（代号R420为X800）于2004年推出，是ATi的一款显卡，以台积电0.13微米Low-k制程生产。只支持DirectX 9.0b，不支持DirectX 9.0c。核心与Radeon 9 Series相似，新的核心只做了些改进。所以不支持 ShaderModel 3.0、HDR等功能。ATi声称X800 XT PE的性能Radeon 9800 XT高出2倍。此系列的X850 XT PE是最快的AGP显卡。

Radeon X1 Series（代号R520为X1800）2005年推出，是ATi的一款显卡，以台积电0.09微米Low-k制程生产，支持DirectX 9.0c。经过重新设计的Radeon X1 Series与前代Radeon X Series核心完全不相类似。Radeon X1 Series亦支持ShaderModel 3.0、HDR等技术，与对手nVIDIA的同代产品平起平坐。

GeForce 6是NVIDIA第六代绘图处理器的总称，其代号为NV40，特色是一个改进了的着色引擎，更节省电力的设计和SLI技术。在支持微软的DirectX 9.0c规格下，全数均支持Vertex及Pixel shader 3.0版。NVIDIA用了10亿美金研发。该系列于2004年4月14日推出 并为GeForce系列的生产线增添了不少新特色，计有Pure Video功能、支持Shader Model 3.0版，以及支持SLI技术。但是产品却仍存在GeForce FX系列的一些缺点，例如ShaderModel 2.0的表现较差。然而在技术及市场上，NVIDIA仍可以GeForce 6系列来与ATI同类产品竞争。NVIDIA声称NV40核心性能比NV38提升一倍。整体而言GeForce 6完全在高端市场击败ATi的Radeon X Series。

GeForce 7是NVIDIA第七代绘图处理器的总称代号为G7x，支持DirectX 9.0C，'Windows Display Driver Model'，OpenGL 2.0。这系列改进了着色效率，率先支持TSAA和TMAA抗锯齿技术，亦支持SLI、vP引击。GeForce 7 3D引擎升级为CineFX 4.0。全系列绘图芯片是原生PCI-E，并没有原生AGP产品推出。与GeForce 6一样，支持Shader Model 3.0，HDR。nVidia声称GeForce 7的Pixel Shader单元运算能力比GeForce 6强两倍。不少人认为G70核心只是旧NV40的改良版。

Geforce 7800 GTX（核心代号为G70），核心采用较成熟的TSMC 0.11微米制程，而不是90纳米制程。可能NVIDIA吸取了当年NV30太早引进0.13微米制程的教训，良率很差。而ATi则采用不成熟的90纳米制程，令Radeon X1000系列延期很久才能推出。

GeForce 8系列，代号G80，是NVIDIA的第八代GeForce显示芯片，支持DirectX 10，OpenGL 3.3，采用统一管线结构。它是由顶点、几何和像素着色引擎（统称SM 4.0）组成。支持Luminex引擎、CSAA抗锯齿技术、Quantum Effects、B2P（8600GT/GTS/8500GT/8400 GS系列）引击和改良后的vP引击。。在7900 GTX发布后八个月，NVIDIA于2006年11月推出GeForce 8800 GTX，它是建基于G80核心。G80是全球首款支持DirectX 10的显示芯片，核心的架构和技术比前代GeForce 7系列显示芯片有很大的不同。纵使它是为DirectX 10而设计，但由于架构的改进，G80在DirectX 9环境下仍可以发挥出强大的性能。

ATI Radeon HD 2000系列，核心代号Radeon R600，是由AMD-ATI开发的一个显示核心产品线。全系列都支持DirectX 10.0，并采用统一渲染架构。对比上一代，ATI增强了其视频播放能力，并可输出音效信号。系列首张显卡HD 2900XT在2007年5月14日发表，它拥有 512 MB GDDR3 内存。分别命名为RV630与RV610的主流与低价产品在2007年7月推出，并以65纳米制程制造。

在2006年7月25日，AMD宣布已经完成并购ATI，而ATI会变成AMD的子公司。这一事件造成有些人担心ATI Radeon Graphics的品牌会从此消失。不过，AMD发布的显示芯片与显卡还是挂上了ATI Radeon Graphics的品牌。Radeon HD 2000系列显卡是ATI被AMD收购后的第一个显卡产品线。它的对手是NVIDIA的GeForce 8系列显卡。采用HD为前缀，解释为强调其高清播放功能，并能随时体验到高分辨率的快感。

ATI Radeon HD 3000系列，代号Radeon R670，是ATi被AMD收购以后推出的第二个Radeon系列图形处理器。Radeon HD 3000系列的架构和上一代Radeon HD 2000系列（代号Radeon R600）的基本一致。但不同的是，Radeon HD 3000系列采用55纳米制程，上代产品采用的是80纳米或65纳米制程。单片机顶级产品Radeon HD 3870相较于上代的旗舰型号Radeon HD 2900 XT，降低了显示内存位宽，核心时钟频率亦有所提升，性能亦有进步，但功耗则大幅降低。在Radeon HD 2000系列推出不到一年，2007年11月15日，AMD发布基于RV670显示核心的Radeon HD 3800系列显卡，以55纳米制程制造，支持DirectX 10.1，并首次于中高级和旗舰产品中加入UVD，提供硬件视频解码。

GeForce 9系列，代号D9E，是NVIDIA的第九代GeForce显示芯片，首个产品GeForce 9600 GT于2008年2月尾推出。9系列拥有65nm制程的高级D9E和55nm制程中阶的D9P两种型号，两者皆支持DirectX 10和Shader Model 4.0，OpenGL 3.3。08年二月尾先上市的是高级的D9E，D9P则在同年六月推出。2009年初，NVIDIA将GeForce 9系列多数型号重新更名为GeForce 100系列，规格只在频率上有部分提升。

GeForce 100－代号同样为G9x，支持DirectX 10、OpenGL 3.2，均为GeForce 9系列的更名产品，仅提供于OEM。

ATI Radeon HD 4000系列，其显示核心代号Radeon R700，由AMD（ATI）研发并推出。Radeon HD 4000系列的第一款产品是RV770显示核心，采用此芯片的显卡为Radeon HD 4850，有800个流处理器。而核心频率更高的HD 4870及HD 4890紧随其后，更率先采用GDDR5作为显示内存。最高端显卡采用R700核心，是一款双芯片显卡产品，名为HD 4870 X2。

GeForce 200系列是NVIDIA的第十代GeForce显示芯片，核心架构代号‘Tesla’，以塞尔维亚裔发明家兼物理学家尼古拉·特斯拉命名，内部代号为G2xx，支持DirectX 10、OpenGL 3.2，部分后期型号支持DirectX 10.1与支持GDDR5显示内存，运算性能两倍于上代，而且其首发的高级显卡 - GTX 280以单GPU胜过GeForce 9800GX2的双GPU。其高性能带来的也包括用电量上升。首个产品GeForce GTX 280于2008年6月16日推出，是一款高端产品。随后推出了中高级的GTX 260。GTX 200系列拥有65nm制程的高级D10。与AMD不同，NVIDIA依然先推出旗舰级显卡，再将其功能削减，成为中低端的显卡。面对着对手AMD的Radeon R700显示核心，GTX 200显示核心显得太复杂和成本高，不能与之有效竞争。所以NVIDIA即时将GeForce 9800 GTX降价，并提升其制程至55nm，再推出GeForce 9800 GTX+显卡。在2009年1月8日开幕的CES 2009电子大展推出55nm版本的GTX 260核心及两款新卡GTX 285、GTX 295。

ATI Radeon HD 5000系列，是AMD的显示核心系列产品，研发代号Evergreen。2007年AMD公司在台湾参加台北国际电脑展览会，展会结束后，公司工程师到酒吧享乐，并提议利用酒店集团名称Evergreen作为新显示核心的代号。整个系列的第一款产品是RV870/Cypress显示核心，采用此芯片的显卡名为Radeon HD 5870，于2009年9月23日推出。核心拥有1600个流处理器，数量是上一代的两倍。它是AMD首个支持DirectX 11的显示核心系列。同时针对OpenCL而设计，加强显示核心的通用运算能力。此外，其ATI Eyefinity技术，可以使显卡支持多屏幕输出。数量最多可以支持六个屏幕输出。

NVIDIA GeForce 300系列是NVIDIA的第十一代GeForce显示芯片，代号为G21x，支持DirectX 10.1、OpenGL 3.2，和前代NVIDIA GeForce 100一样是旧系列图形处理器的更名版，或是基于旧有图形处理器推出的新型号显卡，而且只供OEM使用，无零售版本。GeForce 300仍采用TSMC的55纳米或65纳米制程来制造，中低端产品会采用新型SDDR3显示内存，部分低阶产品更名自GeForce 200系列，一些型号更是基于NVIDIA GeForce 9系列的显示核心，支持Direct 10或10.1

GeForce 400系列，代号为GF10x，支持DirectX 11、OpenGL 4.1、OpenCL 1.1，首次配备GDDR5显示内存，2010年3月26日推出，是NVIDIA的第十二代GeForce显示芯片。采用TSMC的40nm制程，高级型号将首次采用GDDR5显示内存，中低端产品会采用新型SDDR3显示内存。

该系列产品在最初准备发表时，人们曾认为将命名为GeForce 300系列，但在2010年2月初，nVIDIA通过在Twitter和Facebook的官方账户发出消息，下一代Fermi核心的首发两款产品将被命名为GeForce 400系列，分别为GTX 470和GTX 480。而GeForce 300系列将使用在OEM市场，就像之前的GeForce 100系列。

由于NVIDIA需要针对DirectX 11而重新设计显示核心，所以GTX 480的推出比对手AMD慢了不少。

AMD Radeon HD 6000系列，是AMD的显示核心系列产品，研发代号Northern Islands发布于2010年。核心采用40nm制程。Northern Islands原来的设计是采用台积电(TSMC)的32nm 制程，由于TSMC取消32nm 制程的研发改为研发28nm 制程。因此AMD只好改为采用40nm 制程。除了Radeon HD 6900系列外，其余核心的基本架构与上一代的RV870相近。AMD声称将核心的资源重新分配，研发出Radeon HD 6800的Barts核心。Radeon HD 6870的流处理器数量比上一代的Radeon HD 5850还要少。由于采用相同制程，核心面积因而缩小。不过，前者核心的工作频率有大幅的提升，以致其几何表现亦比较优胜。就整体性能而言，Radeon HD 6870比Radeon HD 5870略差；Radeon HD 6850亦比Radeon HD 5850略差。这个新系列显示核心主要有两个改进，一是增强其Tessellation性能，二是增强了AA/AF的性能和质量。

GeForce 500系列是NVIDIA的第十三代GeForce显示芯片。同GeForce 400系列一样采用TSMC的40nm制程，支持DirectX 11、OpenGL4.1、OpenCL 1.1。GeForce 500系列是GeForce 400系列的改进版。首款产品GeForce GTX 580于2010年11月8日推出。2011年1月5日的CES上NVIDIA推出GeForce 500M系列移动显卡，以及采用GF119M的GeForce 410M与GeForce 315M。GeForce 400中，原本设计的GTX480拥有512个流处理器，但为了提高良品率，所以最终削减为480个。而GTX580则真正拥有512个流处理器，是完整版Fermi核心。除了流处理器数量外，显示核心频率亦有所提升。PolyMorph引擎亦由15个增加为16个。提升Tesselation性能。虽然GTX480和GTX580都采用40nm工艺制造，但NVIDIA声称后者采用改良过的版本。就算两者的频率以至流处理器数量相同的情况下，NVIDIA声称后者比前者有10%左右的性能增幅。在电能管理方面，GTX 580新增硬件电压监控和调整。它可以因应个别程序，而动态调整供电强度。采用LFPAK封装的MOSFET，可以提高供电效率减少浪费。而显示核心则采用6相供电，显示内存则采用另外独立的2相供电。

由于某种原因，从GeForce 500开始，由面向玩家发烧友市场的GeForce GTX系列取代面向普通性能市场的GeForce GTS系列。

GeForce 600系列是NVIDIA的第十四代GeForce显示芯片，代号为GK10x，支持DirectX 11、OpenGL4.2、OpenCL 1.1。GeForce 600首次发布于2011年12月6日，型号是GeForce 610M、GeForce GT 630M、GeForce GT 635M，均为上一代Fermi架构的移动版GPU。真正全新一代Kepler架构的产品于2012年3月22日正式发表，命名为GeForce GTX 680，竞争对手为AMD Radeon HD 7970。在发表的同时NVIDIA宣布更换沿用6年之久的GeForce Logo，着力于打造全新的GeForce品牌形象。开普勒架构以约翰内斯·开普勒命名，本身实际基于Fermi设计，核心由费米的流处理器群改为SMX，其中同样以CUDA核心、升级后的PolyMorph 2.0和Texture Units等组成，而每组CUDA核心的数量大幅增加，如GK104的CUDA核心数量为每组192，上代GF110为每组32个，数量是其6倍。GK104核心以两组SMX构成一个GPC单元，核心共有四组GPC单元和四组Raster引擎，之间共享有768KB L2缓存，GK104核心内含四组64bit内存控制器，共支持256bit内存，比上代GF110的384bit低。但GDDR5显示内存的频率提升，可以弥补有关减少。同时开普勒架构核心支持GPU Boost动态超频技术，通过PCB内置的芯片与BIOS控制，会根据GPU的TDP与实际运作功耗之间的差异来进行动态超频。其他的特性还包括采用台积电28nm制程工艺，支持PCI-E 3.0，支持全新的反锯齿技术TXAA及垂直同步技术Adaptive VSync。开普勒架构实现了单卡三屏输出（上一代产品只能以SLI方式进行），通过一个HDMI与两个DVI进行输出，同时还可以通过DisplayPort输出，组成3+1显示器模式。

其中GeForce GTX 690采用2颗完整的代号为GK104的显示核心（GK104-355-A2），3072个CUDA核心，核心时钟频率915MHz，4GB容量的512位位宽GDDR5显示内存，外接双8Pin辅助供电。2013年，有硬件玩家发现，公版的Geforce GTX 690仅仅更变PCB背板上GPU芯片邻近的几颗电阻焊接位上的电阻有无或电阻阻值，即可变成Quadro K5000专业绘图卡或是Tesla K10运算加速卡。因为早先的GTX590曾经发生过电容爆炸的事件，而且功耗和发热都比较大，被网友戏称为”核弹”。慢慢地这个名称扩散到n卡的许多型号，尤其是高端部分。2013-12-13，甘肃卫视《揭秘真相》节目中主持人使用被网友改过的百度百科航母杀手词条，一本正经的称GTX 690为一发能摧毁航母战斗群的战术核弹。[详情见bilibili](http://www.bilibili.com/video/av870268/)

AMD Radeon HD 7000系列，是AMD的图形处理器系列产品，研发代号为Southern Islands（翻译为南方群岛），采用28纳米制程，由台积电代工。本系列第一款产品为Radeon HD 7970，于2012年1月16日发布。全系列显示核心采用“次世代图形核心”（Graphics Core Next）架构，针对通用计算而优化。流处理器由4-Ways VLIW SIMD架构（俗称4D架构）改良，亦提升了曲面细分性能。通过ZeroCore Power技术，显示核心待机的时候，功耗小于3W。另外，Radeon HD 7000支持PCI-Express 3.0总线和Direct X 11.1。

AMD Radeon Rx 200系列显示核心，研发代号“Volcanic Islands”（火山岛），是超微半导体所推出的图形处理器系列，接替开发代号“Sea Islands”（即AMD Radeon HD 8000系列）的产品线。Volcanic Islands系列显示核心原预计2014年推出，届时将与对手NVIDIA的Maxwell系列显示核心和英特尔第二代Xeon Phi架构对抗。而实际上，超微于2013年9月业已公布新一代显示核心的部分信息，并将于同年10月15日正式发布。首发的产品都是Radeon HD 7000系列的修订版本，真正基于新显示核心的Radeon R9 290X于2013年10月24日正式贩售。Volcanic Islands系列采用台积电和Common Platform Alliance（通用平台联盟）的28纳米Gate-Last制程来生产。

“Pirates Islands”（海盗群岛）是最后一个以岛屿为研发代号的显示核心系列,接替“Volcanic Islands”系列，为现在的Radeon Rx 300系列；而“Pirates Islands”首发产品则是归类到Rx 200系列的、核心代号“Tonga”的Radeon R9 285。

NVIDIA GeForce 700 系列是NVIDIA公司在2013年发布的第十五代GeForce图形处理器，用于笔记本电脑和台式机。它主要是使用于GeForce 600系列Kepler架构的改进版（芯片代号以‘GK’开头），不过，和GeForce 600系列一样，一些低级型号则仍使用Fermi架构或是其制程升级版。2013年5月23日，首款基于GeForce 700系列显示核心的显卡GeForce GTX 780正式发布，同时也将此前划分至GeForce 600系列的GeForce GTX TITAN重新划分到GeForce 700系列中。

NVIDIA GeForce 700系列的首款显示核心，代号‘GK110’，特别针对通用运算的性能提升而设计，其拥有71亿颗晶体管，而且还会根据负载需要以及各流处理器负载情况来分派运算任务，从而加强并发多任务性能，并尽可能来最优化性能能耗比表现。在‘GK110’上，寄存器堆和2级缓存（L2 cache）的容量和带宽比此前的型号都有所提升。与‘Fermi’架构相比，在SMX/SM流处理器数组的层面上，‘GK110’的寄存器堆容量增至256KB，由65536个32位的寄存器组成。‘GK110’的2级缓存的容量增加到1.5MB，两倍于费米的‘GF110’。2级缓存和寄存器堆的带宽与‘Fermi’架构相比提升了两倍，使得在需要为每条线程分配更多可用寄存器资源时导致的寄存器匮乏的情况下的性能也得到提升，而且，GK110上每条线程可进行定址、搬移的寄存器总数，也由每线程63个寄存器提升到每线程255个寄存器。GK110上，NVIDIA也对GPU的纹理缓存进行修改，使其不仅只用于图形处理，还可以用于通用运算。48KB容量大小的纹理缓存，在运行通用运算时作为只读缓存，专门用于未对齐的内存访问操作。此外，错误侦测功能也被加入，使得依赖于ECC纠错的负载任务更稳定安全。对比GeForce 600系列，GeForce 700系列的部分型号的显示内存由上代0.33ns颗粒改用了更低延迟的0.28ns颗粒，等效频率由6000MHz上升到7000MHz，GPU时钟频率亦有所上升。此外，GeForce 700系列的部分型号还引入了GPU Boost 2.0，令GPU可根据负载需要自动加速到更高频率。英伟达通过驱动程序的支持，在‘Kepler’显示核心上实现了部分DirectX 12的功能。

Titan，Titan Black Edition，Titan Z - 代号为GK110，支持DirectX 11.1、Shader Model 5.0、OpenGL 4.3以及Open CL 1.2，为Kepler系列芯片的完整版本，Titan Z为Titan的双GPU版本，目标市场为高端游戏玩家。

AMD Radeon Rx 300系列显示核心，研发代号“Pirates Islands”，是超微半导体所推出的图形处理器系列。根据超微的显示核心发展路线“Pirates Islands”将接替“Volcanic Islands”（即AMD Radeon Rx 200系列）的产品线。全新核心"Fiji"为首个使用高带宽内存（HBM）的显示核心系列，内存宽度达4096bit，内存总带宽达512GB/s。 Pirates Islands系列显示核心于2015年6月16日美国E3展正式发布，并于当年6月18日展开第一波的销售，第一波销售的卡号皆为AMD Radeon Rx 200系列型号的修订版本，而基于全新核心"Fiji"的R9 Fury系列则于当年6月24日后开始销售。

NVIDIA GeForce 800系列，是英伟达研发的图形处理器产品系列，用于笔记本电脑平台。此代显示核心将采用新的Maxwell微架构（芯片代号将以‘GM’开头），以苏格兰理论物理学家詹姆士·克拉克·麦克斯韦的名字命名。2014年初悄然发表的移动显示核心GeForce 820M，尽管列入GeForce 800系列，但仍采用GeForce 500系列‘Fermi’架构的GF117显示核心，因此仅仅是旧型号显示核心更名而已。首款基于Maxwell微架构的显示核心实际为GeForce 700系列上的GeForce GTX 750以及750 Ti。后来，NVIDIA也陆续发布移动平台的GeForce 800M系列的其他型号，除GeForce 830M、840M、GTX 850M以及GTX 860M以外，其余的均使用旧有显示核心。NVIDIA宣布新一代Maxwell核心的首发两款产品将被命名为NVIDIA GeForce 900系列，分别为GTX 970和GTX 980。而GeForce 800系列将使用在OEM市场，就像之前的GeForce 100和GeForce 300系列。

NVIDIA GeForce 900系列，是英伟达研发的图形处理器产品系列，用于台式机平台和笔记本电脑平台。此代显示核心将采用第二代Maxwell微架构（芯片代号将以‘GM’开头）。NVIDIA宣布新一代Maxwell核心的首发旗舰级产品将被命名为GeForce 900系列，分别为桌面平台的GTX 970、GTX 980、GTX 980 Ti、GTX TITAN X、GTX 950和GTX 960以及移动平台的GTX 960M GTX 970M和GTX 980M、GTX 980 Notebook。GeForce 800系列全为使用在笔记本电脑OEM市场上的移动式显示核心。GeForce GTX 980/970使用“GM204”核心，是Maxwell GPU架构的第二作。它们分别采用了GM204的两个细分型号 GM204-400-A1 以及 GM204-200-A1 芯片，拥有52亿的晶体管规模，芯片面积为398平方毫米(此为NVIDIA公布数据)。由于有制造“GK110”这种大面积芯片的经验，加上面向消费级游戏应用市场而削减该领域中甚少使用的双精度浮点数运算电路单元，使得GPU可以更专精于安放游戏应用更常用的单精度浮点运算电路单元、纹理单元及渲染输出单元。这些因素成了“GM204”芯片用于游戏娱乐应用时，拥有卓越性能功耗比的重要因素之一。

与Kepler架构的GK110相比，尽管GM204架构的运算资源总量从2880个ALU（NVIDIA称为CUDA核心）分别下降到了GeForce GTX 980的2048以及GeForce GTX 970的1664个，Texture Filter Unit则由240个下降到了128个以及104个，但构成后端的ROP在GM204当中被提升到了64个，更庞大的ROP阵列为GM204带来了理想的像素处理能力。

显示内存方面，GeForce GTX 980/970均拥有4个64bit双通道显存控制器组合形成的256bit显存控制单元，也都采用了4096MB的尺寸的显存体系。

GeForce 900系列目前支持OpenGL 4.5、DirectX 12以及OpenCL 1.2。

基于Maxwell架构的显示核心GM204的首发产品是GeForce GTX 970和GTX 980，它们均于2014年9月19日发布。随后还有GeForce GTX 960，该产品于2015年初发布；之后还有2015年6月1日发布的GTX 980 TI以及8月20日发布的GTX 950。而顶级显示核心GM200，被冠以GeForce GTX TITAN X的名号于2015年3月5日公布，除了TITAN X之外，其余的显卡会有不同的厂商生产自制显卡，还会有背板支撑。

随后发表的GeForce GTX 960、950还支持HEVC/H.265硬件编码，以前发表的型号则只支持H.264硬件解码。

GeForce GTX TITAN X - 2015年3月GDC大会上NVIDIA公布此显卡的消息，显示核心代号“GM200”，此显示核心拥有80亿个晶体管，搭配12GiB容量的显示内存；仍使用台积电28nm制程；供电仅使用了6pin+8pin的辅助供电，功耗250瓦，而12GiB的显示内存容量，则各布置于显卡的正背两面，外观保留和TITAN系列的一贯风格但从银色变成了哑光黑，相对于上一代的TITAN(Black、Z)以及GTX980而言没有背板支撑和散热。另外，GTX TITAN X还将配备低温散热风扇停转的功能。

GeForce GTX 980 TI - 2015年6月1日发售，核心代号与GTX TITAN X一样是“GM200”、80亿个晶体管、6GiB显示内存，但一共只有2816个CUDA核心、192个纹理贴图单元、96个输出渲染单元，不过其余的规格与热设计功耗跟TITAN X大致相同，而且与GTX TITAN X相比性能也相差不多，其它的厂商会生厂自制显卡，显示时钟频率会比公板还要高，也会有背板支撑。

GeForce GTX 980和GeForce GTX 970 - 两者均于2014年9月18日发售，核心代号均为“GM204”之显示核心（内置52亿个晶体管）以及4GiB、等效时钟频率7010MHz的GDDR5显示内存。但GTX 980的GM204显示核心是完整版的，共16组SMM数组（一共2048个CUDA核心、128个纹理贴图单元）、64个渲染输出单元、2MiB二级缓存，内存位宽为256比特，带宽224GB/s；而GTX 970的GM204核心则相对完整的GTX 980而言删减了3组SMM数组（这里共384个CUDA核心、24个纹理贴图单元（TMU））以及8个输出渲染单元（ROP）、二级缓存也从2MiB缩减至1.75MiB，内存位宽为224位+32位的结构，带宽192GB/s+28GB/s。

GeForce GTX 960以及GeForce GTX 950 - 前者2015年1月22日发售，核心代号“GM206”，内置有29.4亿颗晶体管，完整规格，拥有8组SMM单元（共1024个CUDA核心、64个纹理贴图单元）、32个输出渲染单元（ROP），使用2GiB或4GiB容量、等效时钟频率7010MHz规格的GDDR5显示内存，内存位宽128位、带宽112GB/s；除了核心时钟频率以外，规格上几乎是“GM204”的一半，用作取代GeForce GTX 760及其派生型号。而GTX 950则于2015年8月20日发售，核心代号与GTX 960的同为“GM206”，但比GTX 960的少了两组SMM单元（而ROP单元数量维持不变），时钟频率参数也比GTX 960的来得低，是GeForce 900系列中阶产品，用来取代750/750TI，只不过热设计功耗进一步降低到90W，仅需要接一个6PIN外挂电源接头；此款型号恢复了在650/650TI以及750/750TI中取消的SLI功能。

GeForce GTX 970 的规格参数争议主要在于显示内存、ROP单元、二级缓存的数量/容量上实际产品与发布宣传时公布的不一致。其中，特别是显示内存访问结构，因为没详细公布出来，而导致用家在一些使用场合上观察到显示内存访问性能上有差异：GTX 970搭载了4GiB容量的GDDR5显示内存，而实际上只有3.5GiB的容量可以全速访问，越过了3.5GiB容量的界限以后的区块几乎没有访问动作，尽管一般使用甚少会越过此界限，但使用这剩余的0.5GiB容量的显示内存访问性能明显下降了。其后越来越多的性能测试以及调查结果，使英伟达承认，GTX 970的显示内存的使用超过3.5GiB容量界限以后性能下降的事实，并对此做出解释道，显卡正式发售前没有事先通知或公布Maxwell架构的显示核心更精细的核心单元屏蔽方式（这种屏蔽方式更有利于良品率和成本控制）。

NVIDIA标榜“Maxwell”GPU微架构是可以完整支持DirectX 12。但是，首款使用DirectX 12的游戏——奇点灰烬，其开发商——Oxide Games游戏工作室，在游戏的开发阶段，发现“Maxwell”架构GPU的显卡，并不能在DirectX 12下发挥出应有的性能（相比DirectX 11下并没有明显的性能进步）。

Oxide Games表示，尽管NVIDIA的官方文宣上宣称GeForce 900系列GPU能使用DirectX 12的所有功能，但是Maxwell的GPU，实际上并不能使用DirectX 12的核心功能——异步运算以及异步渲染管线，而NVIDIA为了实现这些新功能，在驱动程序层级中安插了Shim（一种提供应用程序接口（即API）的驱动库）中介层来实现它们，但这种实现方式，需要占用一定的GPU运算资源。简单来说，NVIDIA采用了软件的方式实现DirectX 12的部分核心功能，因此会造成性能上的折损。

而与之相对，Oxide Games则表示，AMD的GCN GPU架构中已经包含了异步运算及渲染的硬件电路，因此可以无需通过中介层，驱动程序可直接调用硬件电路单元来实现DirectX 12，尽管支持的功能层级是基本的Feture Level 12_0，因此GCN架构的GPU可以凭借DirectX 12在性能测试抑或是游戏性能中获得较为明显的性能提升。

Oxide Games称在于NVIDIA磋商解决性能问题时，却遭到NVIDIA方面向工作室的施压，要求在游戏性能测试中不能使用DirectX 12的异步运算功能，因此工作室方面认为，NVIDIA的GeForce 900系列GPU面对对手AMD同级别的、对DirectX 12的核心功能能顺利支持的GCN架构GPU时会处于劣势。不过在2015年8月4日，Oxide Games方面解释，“我们确实与NVIDIA的人员交流关于异步运算方面的话题，确实，驱动程序方面尚未能完全实现它，但驱动程序却报告它能够实现之”，NVIDIA也正与Oxide Games合作，令900系列能够实现异步运算。由于不像AMD的GCN架构以硬件电路实现异步运算，NVIDIA将必须仰赖驱动程序及其中介层，实现软件层级的队列及软件层级的任务分发器，来转发异步运算任务到其GPU的硬件任务调度器上，令其胜任将运算负荷能分配至GPU中正确的电路单元上的工作。

本系列同时还有针对移动平台发布的GeForce GTX 970M和GTX 980M以及GTX 960M ,GTX 950M 和 GeForce 940M 930M 920M ，后期有从桌面型移植到移动平台的980 Notebook。

NVIDIA于2016年3月无预警推出3款MX型号显示核心——920MX、930MX及940MX，同时也推出910M。930MX与940MX者架构与930M及940M相同，920MX架构则放弃Kelper/Fermi架构改用Maxwell架构；910M则使用Kelper/Fermi架构，然而MX型号的内存及处理器时钟频率比M型号高，同时内存也支持GDDR5，不过有些厂商为了节省成本则仍然使用DDR3内存。

AMD Radeon 400系列显示核心，是AMD所推出的图形处理器系列，开发代号为“Polaris”，以三星14nm FinFET制程（由格罗方德代工），仍基于GCN架构改造而来，仍继续采用GDDR5显示内存。AMD于2016年中的台北国际电脑展上发表核心代号为“Polaris 10”的首款显卡 Radeon RX 480，作为主流级应用，这是AMD自Radeon HD 4000系列以来再次首先发布中高级级别的GPU。竞争对手为NVIDIA的GeForce 10系列。而开发代号为“Vega”的GPU搭载HBM2显示内存，

本代是GCN显示核心架构的第4个版本。本次架构修订中，更换了新的硬件调度器、改进CU的运行效率、显示信号输出单元（支持DisplayPort 1.4 HBR、HDMI 2.0b、HDR10色域）、新版UVD等等。其中新版UVD的加入使本系列GPU拥有HEVC视频硬件加速能力，最高支持到 60FPS @ 4K分辨率并且每个颜色通道拥有10比特的颜色深度。早期的数据显示这个UVD也可对VP9格式进行硬件加速，不过在驱动程序中并没有该功能的接口可供使用。而在2016年12月中，AMD发表了16.12.1版驱动程序，由此GCN架构的GPU全部开放4K分辨率的VP9解码硬件加速（支持杜比系统、HDR 10），此外，还新增了Relive游戏内视频编码功能，支持游戏直播以及游戏视频录制。在17版深红驱动程序以后，支持双联结DVI-D和DVI-I输出最高 4096 × 2304 的分辨率。

NVIDIA GeForce 10系列是英伟达研发并推出的图形处理器系列，被用以取代NVIDIA GeForce 900系列图形处理器。新系列采用帕斯卡微架构来代替之前的麦克斯韦微架构，并采用台积电的16纳米及Samsung的14nm鳍式多闸极晶体管工艺（Fin-FET）来制造。现已推出了Titan Xp Titan X Pascal 、GTX 1080 Ti、GTX 1080和GTX 1070四款旗舰、中阶的GTX 1060(3/6GB)、GTX 1050 Ti(4GB)以及GTX 1050(2GB)以及入门级GT1030。NVIDIA GeForce 10系列的微架构命名为帕斯卡，根据17世纪的法国数学家布莱兹·帕斯卡而得名。

## 附录：显卡制造商

以下公司曾经或正在生产显示芯片或显卡；包含已经倒闭、退出显卡市场或被并购的公司。

    3dfx
    3DLABS
    Accel Graphics
    Avance Logic
    AMD（超微）
    Appian
    Artist Graphics
    Ark Logic
    ATI（冶天，已被AMD收购）
    Canopus（康能普视）
    Cirrus Logic（凌云逻辑）
    Colorgraphic（彩图）
    Creative（创新）
    DEC（迪吉多）
    Diamond Multimedia（帝盟）
    Dynamic Pictures
    Everex
    Genoa（热那亚）
    Headland
    Hercules（大力神）
    I-O DATA
    Intel（英特尔）
    Intense3D
    IXMicro
    Kasan
    Lung Hwa（陇华）
    Macronix（旺宏）
    Matrox（迈创）
    Matsushita（松下）
    Motorola（摩托罗拉）
    Mpact
    NEC（日本电气）
    Number Nine
    NVIDIA（英伟达）
    Orchid（兰花）
    OAK
    PowerVR
    Quantum3D（昆腾3D）
    Realtek（瑞昱）
    RealVision
    Rendition
    S3 Graphics
    Sigma Designs
    SiS（矽统）
    STB Systems
    STMicroelectronics（意法半导体）
    Tandy（坦迪）
    Tech Source
    Trident（泰鼎）
    Tseng Labs（曾氏）
    Western Design Center（西方设计中心）
    Weitek
    XGI（图诚）
    ASUS（华硕）
    GIGABYTE（技嘉）
    MSI（微星）
    EVGA（艾维克）
    PowerColoer（撼讯）
    Galaxy（影驰）
    Zotac

## 附录：色彩深度

色彩深度计算机图形学领域表示在位图或者视频帧缓冲区中储存1像素的颜色所用的位数，它也称为位/像素（bpp）。色彩深度越高，可用的颜色就越多。

色彩深度是用“n位颜色”（n-bit colour）来说明的。若色彩深度是n位，即有2n种颜色选择，而储存每像素所用的位数就是n。常见的有：

    •1位：2种颜色，单色光，黑白二色，用于compact Macintoshes。
    •2位：4种颜色，CGA，用于gray-scale早期的NeXTstation及color Macintoshes。
    •3位：8种颜色，用于大部分早期的电脑显示器。
    •4位：16种颜色，用于EGA及不常见及在更高的分辨率的VGA标准，color Macintoshes。
    •5位：32种颜色，用于Original Amiga chipset。
    •6位：64种颜色，用于Original Amiga chipset。
    •7位：128种颜色
    •8位：256种颜色，用于最早期的彩色Unix工作站，低分辨率的VGA，Super VGA，AGA，color Macintoshes。
    o灰阶，有256种灰色（包括黑白）。若以24位模式来表示，则RGB的数值均一样，例如(200,200,200)。
    o彩色图像，若以24位模式来表示，则RGB的数值均一样，例如(200,200,200)。就是常说的24位真彩，约为1670万色。
    •9位：512种颜色
    •10位:1024种颜色，
    •12位：用于部分硅谷图形系统，Neo Geo，彩色NeXTstation及Amiga系统于HAM mode。
    •16位：用于部分color Macintoshes( 红色占5 个位、蓝色占 5 个位、绿色占 6 个位，所以红色、蓝色、绿色各有 32、32、64 种明暗度的变化总共可以组合出 64K 种颜色 )。
    •24位：有16,777,216色，真彩色，能提供比肉眼能识别更多的颜色，用于拍摄照片。
    •32位：基于24位而生，增加8个位的透明通道

另外有高动态范围影像(High Dynamic Range Image)，这种影像使用超过一般的256色阶来储存影像，通常来说每个像素会分配到32+32+32个bit来储存颜色资讯，也就是说对于每一个原色都使用一个32bit的浮点数来储存.
